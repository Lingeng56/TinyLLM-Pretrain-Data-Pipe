# 01 多源采集与融合（Guidance · 项目级扩展版）

> 目标：把“多源数据接入”做成一个完整小项目，覆盖公开数据集 + 含 URL 数据集 + 可选搜索采集（searxng）+ 论文源（arXiv）。
> 产出：可复现的多源采集管线、统一 schema、来源清单（manifest）、样本审计报告。

---

## 一、你要学会的知识点（尽量全面）

### 1) 多源数据工程的核心思维
- **数据源分层**：dataset_text / dataset_url / web_search / arxiv
- **统一 schema**：多源数据必须以统一结构输出，避免后续清洗分支爆炸
- **可追溯**：每条样本必须能追溯到来源、许可、采集时间
- **可复现**：同一配置应产出一致的采集结果（确定性）

### 2) 合规与许可
- **公开数据集并不等于可任意使用**：要记录 license 字段
- **网页抓取要遵守 robots / 站点协议**
- **论文来源必须记录版权与使用范围**

### 3) 工程实践
- **Connector 模式**：每个来源独立模块，统一输出接口
- **Manifest / 元信息**：记录来源统计、样本量、时间、版本
- **去重策略**：跨来源去重（hash or simhash）

---

## 二、本章要实现的项目流程（端到端）

### Phase 0：设计统一 schema（本章最重要）
建议字段：
```json
{
  "id": "optional",
  "text": "required",
  "source": "source_name",
  "source_type": "dataset_text|dataset_url|web_search|arxiv",
  "lang": "zh|en|...",
  "timestamp": 1700000000,
  "meta": {
    "license": "string",
    "url": "optional",
    "hash": "optional",
    "extra": {}
  }
}
```

### Phase 1：公开数据集（纯文本）
- 推荐来源：wikitext / small-c4 / redpajama 子集
- 输出到 `data/raw/dataset_text/*.jsonl`
- 必须包含 source=dataset_name

### Phase 2：公开数据集（含 URL）
- 目标：拿到“文本 + url”结构，用于后续网页采集对照
- 输出到 `data/raw/dataset_url/*.jsonl`

### Phase 3：可选 searxng 搜索采集
- 输入：从 dataset_text 抽取 query
- 搜索：searxng 返回 url
- 采集：下载页面正文 → 统一 schema
- 输出：`data/raw/web_search/*.jsonl`

### Phase 4：arXiv 论文源
- 采集方式：arxiv API / 公开数据集
- 输出结构：title/abstract/body 拼接成 text
- 输出：`data/raw/arxiv/*.jsonl`

### Phase 5：融合与清单
- 合并所有来源为统一 raw 数据库
- 输出 `reports/source_manifest.json`

---

## 三、分模块执行指南（具体到步骤）

### 1) dataset_text 采集
**步骤**
1. 选择一个公开数据集（如 small-c4）
2. 提取 text 字段
3. 输出 jsonl

**你需要保证**
- schema 字段齐全
- meta.license 有值

---

### 2) dataset_url 采集
**步骤**
1. 选择包含 url 字段的数据集
2. 抽取 text + url
3. 输出 jsonl

---

### 3) web_search（searxng 可选）
**步骤**
1. 从 dataset_text 抽取关键词/短句作为 query
2. searxng 搜索返回 url
3. 抓取网页正文
4. 输出 jsonl

---

### 4) arXiv 采集
**步骤**
1. 使用 arxiv API 获取论文元信息
2. 解析 title/abstract/body
3. 输出 jsonl

---

## 四、推荐的数据源组合（中英文混合）

**纯文本**
- small-c4 (EN)
- wikitext (EN)
- 中文维基子集 (ZH)

**含 URL**
- 带 url 字段的 web crawl 子集

**论文源**
- arxiv API / arxiv dataset

---

## 五、验收标准（必须满足）
- 4 类来源至少 3 类跑通（web_search 可选）
- raw 数据统一 schema
- source_manifest 记录样本量
- 每条样本可追溯

---

## 六、你会学到的能力总结
- 多源数据接入的工业模式
- schema 设计能力
- 合规/许可意识
- 数据可追溯与可复现
- 数据融合与去重策略

---

## 记录区
- 实际命令：
- 遇到的问题：
- 修正点：
